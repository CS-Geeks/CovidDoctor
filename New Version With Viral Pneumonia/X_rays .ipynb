{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1OIRjxXYThZB"
   },
   "source": [
    "    Covid --- 0\n",
    "    Normal --- 1\n",
    "    Pneumonia ---- 2 **bold text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XoQ5-ULW0h0l"
   },
   "outputs": [],
   "source": [
    "pip install -q tflite-model-maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gok9BWoFz3XE"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/tensorflow/examples.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aOgpmGfzlXF6"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import *\n",
    "from sklearn.metrics import *\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OLazemzZlxWg"
   },
   "outputs": [],
   "source": [
    "train_tfrecord = 'XRay_train.tfrecords'\n",
    "test_tfrecord = 'XRay_test.tfrecords'\n",
    "train_percentage = 0.8  # Proportion of training set\n",
    "\n",
    "random.seed(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dj6mQpNu1KMS"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WX7rRO3blx6F"
   },
   "outputs": [],
   "source": [
    "input_path='drive/MyDrive/Dataset/Train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LmHNZ1solx95"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "buffer_size = 512\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "\n",
    "img_size = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qj0cGAydmTKj"
   },
   "source": [
    "**Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pe49ZfSWmA4W"
   },
   "outputs": [],
   "source": [
    "def read_directory():\n",
    "    data_filenames = []\n",
    "    data_labels = []\n",
    "\n",
    "    for filename in os.listdir(input_path + 'Covid'):\n",
    "        data_filenames.append(input_path + 'Covid/' + filename)\n",
    "        data_labels.append(0)\n",
    "\n",
    "    for filename in os.listdir(input_path + 'Normal'):\n",
    "        data_filenames.append(input_path + 'Normal/' + filename)\n",
    "        data_labels.append(1)\n",
    "\n",
    "    for filename in os.listdir(input_path + 'Viral Pneumonia'):\n",
    "        data_filenames.append(input_path + 'Viral Pneumonia/' + filename)\n",
    "        data_labels.append(2)\n",
    "        \n",
    "    data_size = len(data_labels)\n",
    "\n",
    "    tmp_uni = list(zip(data_filenames, data_labels))\n",
    "\n",
    "    random.shuffle(tmp_uni)\n",
    "\n",
    "    train_size = int(data_size * train_percentage)\n",
    "    print('Size of training set：', train_size)\n",
    "    print('Size of test set：', data_size - train_size)\n",
    "\n",
    "    train_list = tmp_uni[0:train_size]\n",
    "    test_list = tmp_uni[train_size:]\n",
    "\n",
    "    train_filenames, train_labels = zip(*train_list)\n",
    "    test_filenames, test_labels = zip(*test_list)\n",
    "\n",
    "    return train_filenames, train_labels, test_filenames, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aI7C7sZhmbGp"
   },
   "source": [
    "**Build TFRecord**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WTPbr46dmA9d"
   },
   "outputs": [],
   "source": [
    "def build_train_tfrecord(train_filenames, train_labels):  # Generate TFRecord of training set \n",
    "    with tf.io.TFRecordWriter(train_tfrecord)as writer:\n",
    "        for filename, label in zip(train_filenames, train_labels):\n",
    "            image = open(filename, 'rb').read()\n",
    "\n",
    "            feature = {\n",
    "                'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image])),  \n",
    "                'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))  \n",
    "            }\n",
    "\n",
    "            example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "            writer.write(example.SerializeToString())\n",
    "\n",
    "\n",
    "def build_test_tfrecord(test_filenames, test_labels):  # Generate TFRecord of test set\n",
    "    with tf.io.TFRecordWriter(test_tfrecord)as writer:\n",
    "        for filename, label in zip(test_filenames, test_labels):\n",
    "            image = open(filename, 'rb').read()\n",
    "\n",
    "            feature = {\n",
    "                'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image])),\n",
    "                'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))\n",
    "            }\n",
    "\n",
    "            example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "            writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5VbvF36mhxU"
   },
   "source": [
    "**Decode TFRecord and get data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NHGe7ivMmBBq"
   },
   "outputs": [],
   "source": [
    "def _parse_example(example_string):\n",
    "    feature_description = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "\n",
    "    feature_dict = tf.io.parse_single_example(example_string, feature_description)\n",
    "    feature_dict['image'] = tf.io.decode_png(feature_dict['image'], channels=3)\n",
    "    feature_dict['image'] = tf.image.resize(feature_dict['image'], [img_size, img_size]) / 255.0\n",
    "    return feature_dict['image'], feature_dict['label']\n",
    "\n",
    "\n",
    "def get_train_dataset(train_tfrecord):  # read TFRecord\n",
    "    raw_train_dataset = tf.data.TFRecordDataset(train_tfrecord)\n",
    "    train_dataset = raw_train_dataset.map(_parse_example)\n",
    "\n",
    "    return train_dataset\n",
    "\n",
    "\n",
    "def get_test_dataset(test_tfrecord):\n",
    "    raw_test_dataset = tf.data.TFRecordDataset(test_tfrecord)\n",
    "    test_dataset = raw_test_dataset.map(_parse_example)\n",
    "\n",
    "    return test_dataset\n",
    "\n",
    "\n",
    "def data_Preprocessing(train_dataset, test_dataset):\n",
    "    train_dataset = train_dataset.shuffle(buffer_size)\n",
    "    train_dataset = train_dataset.batch(batch_size)\n",
    "    train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    test_dataset = test_dataset.batch(batch_size)\n",
    "    test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZbPn8qxRmr6i"
   },
   "source": [
    "**Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f-9atORLngs_"
   },
   "outputs": [],
   "source": [
    "def InceptionResNetV2_model():\n",
    "    incp_res_v2 = tf.keras.applications.InceptionResNetV2(weights='imagenet',include_top=False, input_shape=[img_size,img_size,3])\n",
    "    incp_res_v2.trainable= True\n",
    "    model = tf.keras.Sequential([\n",
    "        incp_res_v2,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "        metrics=[tf.keras.metrics.sparse_categorical_accuracy]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MHBDpBd7qJDk"
   },
   "source": [
    "**Train&Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n21PZn9aoifQ"
   },
   "outputs": [],
   "source": [
    "def scheduler(epoch,lr):\n",
    "    if epoch<8:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr*0.9\n",
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4p-hUM4qqMsz"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    time_start = time.time()\n",
    "    \n",
    "    model = InceptionResNetV2_model()\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    train_history = model.fit(train_dataset, epochs=epochs, callbacks=[callback])\n",
    "\n",
    "    model.save('mymodel.h5')\n",
    "    \n",
    "    print('Model saved.')\n",
    "    \n",
    "    time_end = time.time()\n",
    "    print('Training Time:', time_end - time_start)\n",
    "    print('\\n')\n",
    "\n",
    "    return train_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iw9ODNu2qMye"
   },
   "outputs": [],
   "source": [
    "def show_train_history(train_history, index):\n",
    "    plt.plot(train_history.history[index])\n",
    "    plt.title('Train History')\n",
    "    plt.ylabel(index)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0_2C4ZHnqM2Q"
   },
   "outputs": [],
   "source": [
    "def test(test_labels):\n",
    "    test_labels = np.array(test_labels)\n",
    "    model = load_model('mymodel.h5')\n",
    "    \n",
    "    print('Testing:')\n",
    "    \n",
    "    model.evaluate(test_dataset)\n",
    "    \n",
    "    predIdxs = model.predict(test_dataset)\n",
    "    predIdxs = np.argmax(predIdxs, axis=1) \n",
    "\n",
    "    target_names = ['COVID', 'NORMAL', 'Viral Pneumonia']\n",
    "    print('\\n')\n",
    "    print(classification_report(test_labels, predIdxs, target_names=target_names, digits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "woKFWI_Jq5er"
   },
   "source": [
    "**Run Now¶**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GQJgb_kAq060"
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_filenames, train_labels, test_filenames, test_labels = read_directory()\n",
    "\n",
    "    build_train_tfrecord(train_filenames, train_labels)\n",
    "    build_test_tfrecord(test_filenames, test_labels)\n",
    "\n",
    "    train_dataset = get_train_dataset(train_tfrecord)\n",
    "    test_dataset = get_test_dataset(test_tfrecord)\n",
    "\n",
    "    print('Info of train_dataset', type(train_dataset))\n",
    "    print('Info of test_dataset', type(test_dataset))\n",
    "\n",
    "    train_dataset, test_dataset = data_Preprocessing(train_dataset, test_dataset) \n",
    "\n",
    "    train_history = train()\n",
    "    \n",
    "    test(test_labels)\n",
    "    \n",
    "    show_train_history(train_history, 'sparse_categorical_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XY1beCiLq1Ct"
   },
   "outputs": [],
   "source": [
    "model=load_model('mymodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IISEGlbkq1GY"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A0JrcCtPbR9B"
   },
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ojjCmTlpbdce"
   },
   "outputs": [],
   "source": [
    "with open('InceptionResNetV2_model().tflite', 'wb') as f:\n",
    "    f.write(quantized_tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H6GkNDKuq1JU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "coRcIJz_q1NX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F5XBVExpfYv8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dbp-YGyQdtkZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XuK0Rkb9rif4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JRTOwm4qq1RC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FaFQdFiQq1Vd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z8Fezcd3qM59"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ac9lzSSYpH3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M6mgarsPz1yl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "X_rays.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
