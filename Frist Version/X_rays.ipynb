{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "X_rays.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OIRjxXYThZB"
      },
      "source": [
        "    Covid --- 0\n",
        "    Normal --- 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOgpmGfzlXF6"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import *\n",
        "from sklearn.metrics import *\n",
        "from tensorflow.keras.models import load_model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLazemzZlxWg"
      },
      "source": [
        "train_tfrecord = 'XRay_train.tfrecords'\n",
        "test_tfrecord = 'XRay_test.tfrecords'\n",
        "train_percentage = 0.8  # Proportion of training set\n",
        "\n",
        "random.seed(20)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dj6mQpNu1KMS"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX7rRO3blx6F"
      },
      "source": [
        "input_path='drive/MyDrive/COVID-19_Radiography_Dataset/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmHNZ1solx95"
      },
      "source": [
        "learning_rate = 0.001\n",
        "buffer_size = 512\n",
        "batch_size = 32\n",
        "epochs = 20\n",
        "\n",
        "img_size = 224"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qj0cGAydmTKj"
      },
      "source": [
        "**Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe49ZfSWmA4W"
      },
      "source": [
        "def read_directory():\n",
        "    data_filenames = []\n",
        "    data_labels = []\n",
        "\n",
        "    for filename in os.listdir(input_path + 'COVID'):\n",
        "        data_filenames.append(input_path + 'COVID/' + filename)\n",
        "        data_labels.append(0)\n",
        "\n",
        "   \n",
        "    for filename in os.listdir(input_path + 'Normal'):\n",
        "        data_filenames.append(input_path + 'Normal/' + filename)\n",
        "        data_labels.append(1)\n",
        "\n",
        "        \n",
        "    data_size = len(data_labels)\n",
        "\n",
        "    tmp_uni = list(zip(data_filenames, data_labels))\n",
        "\n",
        "    random.shuffle(tmp_uni)\n",
        "\n",
        "    train_size = int(data_size * train_percentage)\n",
        "    print('Size of training set：', train_size)\n",
        "    print('Size of test set：', data_size - train_size)\n",
        "\n",
        "    train_list = tmp_uni[0:train_size]\n",
        "    test_list = tmp_uni[train_size:]\n",
        "\n",
        "    train_filenames, train_labels = zip(*train_list)\n",
        "    test_filenames, test_labels = zip(*test_list)\n",
        "\n",
        "    return train_filenames, train_labels, test_filenames, test_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aI7C7sZhmbGp"
      },
      "source": [
        "**Build TFRecord**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTPbr46dmA9d"
      },
      "source": [
        "def build_train_tfrecord(train_filenames, train_labels):  # Generate TFRecord of training set \n",
        "    with tf.io.TFRecordWriter(train_tfrecord)as writer:\n",
        "        for filename, label in zip(train_filenames, train_labels):\n",
        "            image = open(filename, 'rb').read()\n",
        "\n",
        "            feature = {\n",
        "                'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image])),  # img > Bytes\n",
        "                'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))  # label > Int\n",
        "            }\n",
        "\n",
        "            example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "            writer.write(example.SerializeToString())\n",
        "\n",
        "\n",
        "def build_test_tfrecord(test_filenames, test_labels):  # Generate TFRecord of test set\n",
        "    with tf.io.TFRecordWriter(test_tfrecord)as writer:\n",
        "        for filename, label in zip(test_filenames, test_labels):\n",
        "            image = open(filename, 'rb').read()\n",
        "\n",
        "            feature = {\n",
        "                'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image])),\n",
        "                'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))\n",
        "            }\n",
        "\n",
        "            example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "            writer.write(example.SerializeToString())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5VbvF36mhxU"
      },
      "source": [
        "**Decode TFRecord and get data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHGe7ivMmBBq"
      },
      "source": [
        "def _parse_example(example_string):\n",
        "    feature_description = {\n",
        "        'image': tf.io.FixedLenFeature([], tf.string),\n",
        "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "    }\n",
        "\n",
        "    feature_dict = tf.io.parse_single_example(example_string, feature_description)\n",
        "    feature_dict['image'] = tf.io.decode_png(feature_dict['image'], channels=3)\n",
        "    feature_dict['image'] = tf.image.resize(feature_dict['image'], [img_size, img_size]) / 255.0\n",
        "    return feature_dict['image'], feature_dict['label']\n",
        "\n",
        "\n",
        "def get_train_dataset(train_tfrecord):  # read TFRecord\n",
        "    raw_train_dataset = tf.data.TFRecordDataset(train_tfrecord)\n",
        "    train_dataset = raw_train_dataset.map(_parse_example)\n",
        "\n",
        "    return train_dataset\n",
        "\n",
        "\n",
        "def get_test_dataset(test_tfrecord):\n",
        "    raw_test_dataset = tf.data.TFRecordDataset(test_tfrecord)\n",
        "    test_dataset = raw_test_dataset.map(_parse_example)\n",
        "\n",
        "    return test_dataset\n",
        "\n",
        "\n",
        "def data_Preprocessing(train_dataset, test_dataset):\n",
        "    train_dataset = train_dataset.shuffle(buffer_size)\n",
        "    train_dataset = train_dataset.batch(batch_size)\n",
        "    train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    test_dataset = test_dataset.batch(batch_size)\n",
        "    test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    return train_dataset, test_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbPn8qxRmr6i"
      },
      "source": [
        "**Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-9atORLngs_"
      },
      "source": [
        "def InceptionResNetV2_model():\n",
        "    incp_res_v2 = tf.keras.applications.InceptionResNetV2(weights='imagenet',include_top=False, input_shape=[img_size,img_size,3])\n",
        "    incp_res_v2.trainable= True\n",
        "    model = tf.keras.Sequential([\n",
        "        incp_res_v2,\n",
        "        tf.keras.layers.GlobalAveragePooling2D(),\n",
        "        tf.keras.layers.Dense(2, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "        loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "        metrics=[tf.keras.metrics.sparse_categorical_accuracy]\n",
        "    )\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHBDpBd7qJDk"
      },
      "source": [
        "**Train&Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n21PZn9aoifQ"
      },
      "source": [
        "def scheduler(epoch,lr):\n",
        "    if epoch<8:\n",
        "        return lr\n",
        "    else:\n",
        "        return lr*0.9\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(scheduler,verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4p-hUM4qqMsz"
      },
      "source": [
        "def train():\n",
        "    time_start = time.time()\n",
        "    \n",
        "    model = InceptionResNetV2_model()\n",
        "    \n",
        "    model.summary()\n",
        "    \n",
        "    train_history = model.fit(train_dataset, epochs=20, callbacks=[callback])\n",
        "\n",
        "    model.save('mymodel.h5')\n",
        "    \n",
        "    print('Model saved.')\n",
        "    \n",
        "    time_end = time.time()\n",
        "    print('Training Time:', time_end - time_start)\n",
        "    print('\\n')\n",
        "\n",
        "    return train_history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw9ODNu2qMye"
      },
      "source": [
        "def show_train_history(train_history, index):\n",
        "    plt.plot(train_history.history[index])\n",
        "    plt.title('Train History')\n",
        "    plt.ylabel(index)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_2C4ZHnqM2Q"
      },
      "source": [
        "def test(test_labels):\n",
        "    test_labels = np.array(test_labels)\n",
        "    model = load_model('mymodel.h5')\n",
        "    \n",
        "    print('Testing:')\n",
        "    \n",
        "    model.evaluate(test_dataset)\n",
        "    \n",
        "    predIdxs = model.predict(test_dataset)\n",
        "    predIdxs = np.argmax(predIdxs, axis=1) \n",
        "\n",
        "    target_names = ['COVID', 'NORMAL']\n",
        "    print('\\n')\n",
        "    print(classification_report(test_labels, predIdxs, target_names=target_names, digits=5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woKFWI_Jq5er"
      },
      "source": [
        "**Run Now¶**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQJgb_kAq060"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    train_filenames, train_labels, test_filenames, test_labels = read_directory()\n",
        "\n",
        "    build_train_tfrecord(train_filenames, train_labels)\n",
        "    build_test_tfrecord(test_filenames, test_labels)\n",
        "\n",
        "    train_dataset = get_train_dataset(train_tfrecord)\n",
        "    test_dataset = get_test_dataset(test_tfrecord)\n",
        "\n",
        "    print('Info of train_dataset', type(train_dataset))\n",
        "    print('Info of test_dataset', type(test_dataset))\n",
        "\n",
        "    train_dataset, test_dataset = data_Preprocessing(train_dataset, test_dataset) \n",
        "\n",
        "    train_history = train()\n",
        "    \n",
        "    test(test_labels)\n",
        "    \n",
        "    show_train_history(train_history, 'sparse_categorical_accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgBe11YjfNer"
      },
      "source": [
        "model=load_model('mymodel.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IISEGlbkq1GY"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0JrcCtPbR9B"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "quantized_tflite_model = converter.convert()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojjCmTlpbdce"
      },
      "source": [
        "with open('Covid19.tflite', 'wb') as f:\n",
        "  f.write(quantized_tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8Fezcd3qM59"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ac9lzSSYpH3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6mgarsPz1yl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}